# [Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)

## What is GFS?
GFS is used for Google's data-intensive applications, including web indexing, searching, and crawling.

## What does GFS aim to solve?
GFS is designed for the following observation and assumption:
1. Components(machines, disks) often fail.
2. Multi-GB files are the common case.
3. Large streaming reads and small random reads.
4. Many large, sequential writes that append data to files.
5. Concurrently append to the same file.
6. High sustained bandwidth is more important.

## Architecture
![GFS Architecture](./GFS%20Architecture.png)

A GFS cluster consists of a single master and multiple chunkservers and is accessed by multiple clients.

The 4 steps illustrate a simple read operation. In step 1, the client asks the master for metadata: where are the replicas and locations where my data is stored? The metadata is returned in step 2, and then in step 3, the client asks for one of the replicas (usually the closest one) for the actual data, which is transferred in step 4.

Every client has to interact with the master. If the master started forwarding data to clients, bandwidth would be used up quickly, and the system couldnâ€™t serve many requests. By returning metadata, interactions with the master are quick, while interactions with chunkservers are longer (which is fine, since clients are probably talking to different chunkservers).

## Features
+ Namespace management and locking.
+ Fault tolerance.
+ Reduced client and master interaction because of large chunk server size.
+ High availability.
+ Critical data replication.
+ Automatic and efficient data recovery.
+ High aggregate throughput.
+ week consistency

## Data Flow
![](./Data%20Flow.png)

Each piece of data must be replicated a configurable number of times (by default, 3) for availability. The diagram below shows what happens when a client writes data.

1. The client asks the master to write data.
2. The master responds with replica locations where the client can write.
3. The client finds the closest replica and starts forwarding data. (When a replica starts receiving data, it immediately forwards it to the next closest replica to speed up the process. This continues until all replicas have the data.)
4. The client asks the primary replica to commit the data.
5. The primary commits and asks the secondaries to do the same. If multiple changes happen concurrently, it also sends the order to commit changes.
6. The secondary replicas respond to the primary.
7. The primary responds to the client and reports errors.


### Specify three most important considerations/rationale behind Google to design GFS. Also specify what design choices were made to address these in GFS.
Google designed the Google File System (GFS) to address the challenges of storing and managing vast amounts of data across a distributed infrastructure. Three important considerations or rationales behind the design of GFS include:

1. Scalability:
   - **Consideration/Rationale**: Google needed a file system that could scale seamlessly to accommodate the massive amounts of data generated by its services and applications. Traditional file systems were not designed to handle such scale efficiently.
   - **Design Choices in GFS**: GFS employs a distributed architecture where data is spread across multiple storage nodes called chunkservers. This allows GFS to handle petabytes of data by distributing it across a large number of machines. Additionally, GFS utilizes a master server to coordinate operations and metadata management, ensuring scalability without sacrificing performance.

2. Fault Tolerance:
   - **Consideration/Rationale**: With a large number of machines in a distributed environment, failures are inevitable. Google needed a file system that could tolerate failures gracefully without compromising data integrity or availability.
   - **Design Choices in GFS**: GFS achieves fault tolerance through data replication. Each chunk of data is replicated across multiple chunkservers, typically three replicas. If one chunkservers fails, the data can still be accessed from the other replicas. GFS also employs automatic and transparent recovery mechanisms to maintain data consistency and availability in the event of failures.

3. High Throughput:
   - **Consideration/Rationale**: Google's applications require high throughput for reading and writing data. Traditional file systems often become bottlenecks when handling large volumes of data and concurrent access.
   - **Design Choices in GFS**: GFS is optimized for streaming reads and writes, making it suitable for Google's data-intensive applications. It employs large chunk sizes (typically 64 MB) to minimize the overhead of metadata operations, reducing the impact of frequent small reads and writes. Additionally, GFS employs a relaxed consistency model, allowing for higher throughput by sacrificing strict consistency guarantees in favor of performance.